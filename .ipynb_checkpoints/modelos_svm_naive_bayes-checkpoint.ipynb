{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Início\n",
    "\n",
    "Aqui já estamos com os dados processados, isto é, foi realizado a limpeza de caracteres indesejáveis, aplicado stemming e stopwords. Primeiro, vamos fazer uma visualização da estrutura do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((651, 3), (322, 3))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "treino = pd.read_csv(\"base_treino.csv\", sep=\",\")\n",
    "teste = pd.read_csv(\"base_teste.csv\", sep = \",\")\n",
    "treino.shape, teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>CLASSIFICAÇÃO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>vou procur outr banc segund abr cont pj vou ca...</td>\n",
       "      <td>marca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>805</td>\n",
       "      <td>rt lib googl pay prfv</td>\n",
       "      <td>marca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>832</td>\n",
       "      <td>ola consig pag bolet app vc manutenca la</td>\n",
       "      <td>produto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>log hoj cancel carta atend</td>\n",
       "      <td>marca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1160</td>\n",
       "      <td>rt faz cobranc indev segund gerent reembols do...</td>\n",
       "      <td>produto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           conteudo CLASSIFICAÇÃO\n",
       "0    223  vou procur outr banc segund abr cont pj vou ca...         marca\n",
       "1    805                              rt lib googl pay prfv         marca\n",
       "2    832           ola consig pag bolet app vc manutenca la       produto\n",
       "3    152                         log hoj cancel carta atend         marca\n",
       "4   1160  rt faz cobranc indev segund gerent reembols do...       produto"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words trata-se de uma técnica onde transformamos vetores de palavras em vetores reais, requeridos pelos algoritmos que iremos utilizar. Como isto é feito? Cada palavra é *tokenizada*, isto é, cria-se uma coluna ou feature com a palavra e para cada linha indica-se se há ou não a presença desta no documento (*tweet*), seja com um vetor binário indicando presença/ausência, seja com a contagem destas. Porém, a ordem das palavras é perdida, o que pode acarretar em problemas pois a ordem tem implicações semânticas e sintáticas e contém informações que podem ser extremamente relevantes para a performance do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos vetorizar o conteudo dos tweets utilizando a biblioteca TfIdfVectorizer. Tabelas tf-idf são utilizadas para dar importância à frequência da palavra por tweet (term-frequency), porém diminui o peso dela se a palavra aparece em muitos documentos (inverse-document frequency), pois assim ela torna-se mais irrelevante para tarefa de diferenciação dos tópicos, como por exemplo, artigos, pronomes, ou preposições, podem ser consideradas irrelevantes para a tarefa de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((651, 1649), (651,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_model = TfidfVectorizer().fit(treino.conteudo.values.astype('U'))\n",
    "X_treino = tfidf_model.transform(treino.conteudo.values.astype('U'))\n",
    "X_teste = tfidf_model.transform(teste.conteudo.values.astype('U'))\n",
    "y_treino = treino.CLASSIFICAÇÃO\n",
    "y_teste = teste.CLASSIFICAÇÃO\n",
    "X_treino.shape, y_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar o algoritmo Naive Bayes então, e verificar a performance do classificador na base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_treino, y_treino)\n",
    "y_pred = clf.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.777451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.599034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.579611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.708075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                scores\n",
       "precision     0.777451\n",
       "recall        0.599034\n",
       "fscore        0.579611\n",
       "distribution       NaN\n",
       "accuracy      0.708075"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def scores(y_true, y_pred):\n",
    "    avg_train_scores = precision_recall_fscore_support(y_true, y_pred, \n",
    "                                average = 'macro', \n",
    "                                labels = ['produto', 'marca'])\n",
    "    scores_ = list(avg_train_scores)\n",
    "    scores_.append(accuracy_score(y_true, y_pred))\n",
    "    return pd.DataFrame(scores_, \n",
    "             columns = ['scores'],\n",
    "             index = ['precision', 'recall', 'fscore', 'distribution', 'accuracy'])\n",
    "scores(y_teste, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que temos um resultado satisfatório, isto é, acima do nosso baseline de 64%, que seria um modelo obtido escolhendo todas as classes como sendo **Marca.** Antes de procedermos com a utilização de algoritmos mais robustos como Support Vector Machines, vemos verificar como nosso modelo está com relação ao overfitting, e sua variância com relação as amostras retiradas de cada um. Para isso, vamos utilizar cross validation e o método do **K-Fold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.818152</td>\n",
       "      <td>0.591098</td>\n",
       "      <td>0.568898</td>\n",
       "      <td>0.718894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.600996</td>\n",
       "      <td>0.584192</td>\n",
       "      <td>0.705069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.830625</td>\n",
       "      <td>0.662071</td>\n",
       "      <td>0.681974</td>\n",
       "      <td>0.792627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.791618</td>\n",
       "      <td>0.650110</td>\n",
       "      <td>0.664712</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.722716</td>\n",
       "      <td>0.582394</td>\n",
       "      <td>0.562025</td>\n",
       "      <td>0.700461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.768714</td>\n",
       "      <td>0.612582</td>\n",
       "      <td>0.604592</td>\n",
       "      <td>0.723502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.562009</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.592228</td>\n",
       "      <td>0.579036</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.797496</td>\n",
       "      <td>0.638270</td>\n",
       "      <td>0.649548</td>\n",
       "      <td>0.769585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.752396</td>\n",
       "      <td>0.619572</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.746544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.695875</td>\n",
       "      <td>0.554151</td>\n",
       "      <td>0.508120</td>\n",
       "      <td>0.663594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>0.649548</td>\n",
       "      <td>0.769585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.606022</td>\n",
       "      <td>0.596285</td>\n",
       "      <td>0.728111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.780918</td>\n",
       "      <td>0.553339</td>\n",
       "      <td>0.498225</td>\n",
       "      <td>0.672811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>0.754367</td>\n",
       "      <td>0.645731</td>\n",
       "      <td>0.660513</td>\n",
       "      <td>0.769585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision    recall    fscore  accuracy\n",
       "scores   0.818152  0.591098  0.568898  0.718894\n",
       "scores   0.755245  0.600996  0.584192  0.705069\n",
       "scores   0.830625  0.662071  0.681974  0.792627\n",
       "scores   0.791618  0.650110  0.664712  0.774194\n",
       "scores   0.722716  0.582394  0.562025  0.700461\n",
       "scores   0.768714  0.612582  0.604592  0.723502\n",
       "scores   0.844828  0.590909  0.562009  0.709677\n",
       "scores   0.735544  0.592228  0.579036  0.714286\n",
       "scores   0.797496  0.638270  0.649548  0.769585\n",
       "scores   0.752396  0.619572  0.623656  0.746544\n",
       "scores   0.695875  0.554151  0.508120  0.663594\n",
       "scores   0.831469  0.640347  0.649548  0.769585\n",
       "scores   0.782868  0.606022  0.596285  0.728111\n",
       "scores   0.780918  0.553339  0.498225  0.672811\n",
       "scores   0.754367  0.645731  0.660513  0.769585"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos usar o RepeatedKFold, que gera KFold n vezes. Nosso objetivo é analisar a variância do modelo\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "def repeatedKfold(n_splits=3, n_repeats=3):\n",
    "    rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    data_frame = []\n",
    "    n = 1\n",
    "    for train_index, test_index in rkf.split(X_treino):\n",
    "        train, test = X_treino[train_index], X_treino[test_index]\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(train, y_treino[train_index])\n",
    "        y_new_pred = clf.predict(test)\n",
    "        data_frame.append(scores(y_treino[test_index], y_new_pred).T)\n",
    "        \n",
    "    return data_frame\n",
    "\n",
    "df = pd.concat(repeatedKfold(3,5))\n",
    "df.drop('distribution', inplace=True, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando os valores médios, obtemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>Precisão</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.730568</td>\n",
       "      <td>0.777522</td>\n",
       "      <td>0.609321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desvio Padrao</th>\n",
       "      <td>0.038590</td>\n",
       "      <td>0.042864</td>\n",
       "      <td>0.033418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Acurácia  Precisão    Recall\n",
       "Media          0.730568  0.777522  0.609321\n",
       "Desvio Padrao  0.038590  0.042864  0.033418"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame({\"Precisão\":[df.precision.mean(), df.precision.std()],\n",
    "                     \"Recall\": [df.recall.mean(), df.recall.std()],\n",
    "                     \"Acurácia\": [df.accuracy.mean(), df.accuracy.std()]}, \n",
    "                         index = [\"Media\", \"Desvio Padrao\"])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos um desvio padrão baixo e uma média de acurácia maior que o nosso baseline, portanto somos capazes de realizar melhor que um modelo aleatório."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora aplicar outro algoritmo, dito mais robusto e capaz de performar melhor em diversos tópicos que o Naive Bayes, **Support Vector Machines** ou SVM com kernek linear. Diferentemente do NB, entretanto, o SVM possui hiperparâmetros a serem ajustados, como o parâmetro C, ligado ao custo que cada **slack variable** gera para o modelo. Lembrando que um C alto indica que o modelo é mais restrito e o custo é alto para variáveis fora da margem de classificação, podendo causar **overfitting**. Já para valores baixos de C, o modelo não é tão restrito, e mais variáveis ultrapassam a margem de classificação, C menores evitam overfitting, porém podem causar **underfitting**. \n",
    "Portanto, a escolha do C ótimo torna-se essencial para o problema de classificação, e faremos isso utilizando o Grid Search, um método de busca forçada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'C':[0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1,2,3,4,5, 10, 50, 100]}\n",
    "svm = LinearSVC()\n",
    "clf_gs = GridSearchCV(svm, parameters, cv=3)\n",
    "clf_gs.fit(X_treino, y_treino)\n",
    "clf_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.692649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.664251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.670923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.717391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                scores\n",
       "precision     0.692649\n",
       "recall        0.664251\n",
       "fscore        0.670923\n",
       "distribution       NaN\n",
       "accuracy      0.717391"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=2)\n",
    "svm.fit(X_treino, y_treino)\n",
    "y_pred_svm = svm.predict(X_teste)\n",
    "\n",
    "scores(y_teste, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vemos que a performance do SVM não é superior ao Naive Bayes, indicando possivelmente que precisamos de outras formas de análise ao invés de algoritmos diferentes. Vamos aplicar o conceito de **n-grams** e analisar os resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram\n",
    "\n",
    "N-gram trata-se de um conceito onde tentamos preservar parte da ordem das palavras provindas dos documentos. Na utilização do bag-of-words, temos que cada palavra é transformada em um vetor real e sua ordem é perdida. Quando utilizamos então o termo n-gram, estamos tokenizando conjunto de palavras, definidos pela variável n, assim sendo, agora ao invés de cada coluna ser uma palavra, teremos colunar de duas ou três palavras, em forma de janelamento. Como exemplo:\n",
    "\n",
    "    \"Tenho problemas no meu cartão de crédito\"\n",
    "BoW: \n",
    "\t- Tenho: 1\n",
    "\t- problemas: 1\n",
    "\t- no: 1\n",
    "\t- meu: 1\n",
    "\t- cartão: 1\n",
    "\t- de: 1\n",
    "\t- crédito: 1\n",
    "2-grams:\n",
    "\t- Tenho problemas: 1\n",
    "\t- problemas no: 1\n",
    "\t- no meu: 1\n",
    "\t- meu cartão: 1\n",
    "\t- cartão de: 1\n",
    "\t- de crédito: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((651, 6043), (651,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criamos n-grams alterando o parâmetro ngram_range=(2,2) dentro da classe TfidfVectorizer.\n",
    "\n",
    "tfidf_model = TfidfVectorizer(ngram_range= (2,2)).fit(treino.conteudo.values.astype('U'))\n",
    "X_treino = tfidf_model.transform(treino.conteudo.values.astype('U'))\n",
    "X_teste = tfidf_model.transform(teste.conteudo.values.astype('U'))\n",
    "y_treino = treino.CLASSIFICAÇÃO\n",
    "y_teste = teste.CLASSIFICAÇÃO\n",
    "X_treino.shape, y_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.757686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.562319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.519403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.683230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                scores\n",
       "precision     0.757686\n",
       "recall        0.562319\n",
       "fscore        0.519403\n",
       "distribution       NaN\n",
       "accuracy      0.683230"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_treino, y_treino)\n",
    "y_pred = clf.predict(X_teste)\n",
    "scores(y_teste, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.674078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.616425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.616890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                scores\n",
       "precision     0.674078\n",
       "recall        0.616425\n",
       "fscore        0.616890\n",
       "distribution       NaN\n",
       "accuracy      0.695652"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=2)\n",
    "svm.fit(X_treino, y_treino)\n",
    "y_pred_svm = svm.predict(X_teste)\n",
    "\n",
    "scores(y_teste, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com 2-grams não vemos uma melhora clara na performance do classificador. Vamos utilizar o GridSearch novamente e verificar para mais valores e variando alguns outros parâmetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "clf_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2), (2, 2), (2, 3), (1, 3)], 'tfidf__use_idf': (True, False), 'clf__C': [1, 1.4, 1.5, 1.6, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2), (2, 3), (1, 3)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "              'clf__C': [1,1.4,1.5,1.6, 2] }\n",
    "\n",
    "gs_clf = GridSearchCV(clf_pipeline, parameters)\n",
    "gs_clf.fit(treino['conteudo'], treino['CLASSIFICAÇÃO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tupla de n_gram representada aqui significa que vamos tokenizar as palavras tanto uma a uma como com janelamento de n=2, assim, como demonstração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aqui': 0,\n",
      " 'aqui sempre': 1,\n",
      " 'atendido': 2,\n",
      " 'atendido consegui': 3,\n",
      " 'atendimento': 4,\n",
      " 'atendimento por': 5,\n",
      " 'consegui': 6,\n",
      " 'consegui resolver': 7,\n",
      " 'fui': 8,\n",
      " 'fui atendido': 9,\n",
      " 'itau': 10,\n",
      " 'itau já': 11,\n",
      " 'já': 12,\n",
      " 'já fui': 13,\n",
      " 'mas': 14,\n",
      " 'mas obrigado': 15,\n",
      " 'melhor': 16,\n",
      " 'obrigado': 17,\n",
      " 'obrigado pela': 18,\n",
      " 'pela': 19,\n",
      " 'pela presteza': 20,\n",
      " 'por': 21,\n",
      " 'por aqui': 22,\n",
      " 'presteza': 23,\n",
      " 'presteza atendimento': 24,\n",
      " 'resolver': 25,\n",
      " 'resolver situação': 26,\n",
      " 'sempre': 27,\n",
      " 'sempre melhor': 28,\n",
      " 'situação': 29,\n",
      " 'situação mas': 30}\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import pprint\n",
    "\n",
    "tweet = [\"itau Já fui atendido e consegui resolver a situação. Mas obrigado pela presteza, o atendimento por aqui é sempre melhor?\"]\n",
    "tfidf_model = TfidfVectorizer(ngram_range= (1,2)).fit(tweet)\n",
    "pprint.pprint(tfidf_model.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, com o resultado obtido, vamos usar a base de testes para validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.713559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.692271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.698950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.736025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                scores\n",
       "precision     0.713559\n",
       "recall        0.692271\n",
       "fscore        0.698950\n",
       "distribution       NaN\n",
       "accuracy      0.736025"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model = TfidfVectorizer(ngram_range= (1,2)).fit(treino.conteudo.values.astype('U'))\n",
    "X_treino = tfidf_model.transform(treino.conteudo.values.astype('U'))\n",
    "X_teste = tfidf_model.transform(teste.conteudo.values.astype('U'))\n",
    "y_treino = treino.CLASSIFICAÇÃO\n",
    "y_teste = teste.CLASSIFICAÇÃO\n",
    "X_treino.shape, y_treino.shape\n",
    "\n",
    "svm_final = LinearSVC(C=1)\n",
    "svm.fit(X_treino, y_treino)\n",
    "y_pred_final = svm.predict(X_teste)\n",
    "scores(y_teste, y_pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos um aumento na acurácia do classificador, não muito relevante, mas de uma forma satisfatória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, nosso resultado final foi um classificador com 73% de acurácia, o que está acima do baseline e cumpre muito bem o objetivo do projeto. Mostramos de forma quantitativa que é viável realizar uma distinção de tópicos somente utilizando dados de mídias sociais, agilizando o processo de tomada de decisão dos operadores e criando um fluxo de trabalho em que o atendimento é mais rápido e confiável.\n",
    "\n",
    "Antes de finalizar, gostaria de prestar alguns pontos:\n",
    "    - O classificador pode obter um resultado melhor com mais dados treinados.\n",
    "    - Existem outros métodos a melhorar o algoritmo não citados aqui, bem como uma análise mais profunda dos motivos de o classificador se confundir, como técnica de redução de dimensionalidade, clusterização, engenharia de atributos mais robusta, entre outros.\n",
    "    \n",
    "Vocês podem verificar o notebook completo, bem como os dados utilizados no [reposótio do github](https://github.com/vtoliveira/programa-talento-acao).\n",
    "\n",
    "Dúvidas, críticas ou sugestões são muito bem-vindas.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
